{
  "version": 3,
  "sources": ["../../../../../../front_end/entrypoints/formatter_worker/AcornTokenizer.ts"],
  "sourcesContent": ["// Copyright (c) 2014 The Chromium Authors. All rights reserved.\n// Use of this source code is governed by a BSD-style license that can be\n// found in the LICENSE file.\n\nimport * as Platform from '../../core/platform/platform.js';\nimport * as TextUtils from '../../models/text_utils/text_utils.js';\nimport * as Acorn from '../../third_party/acorn/acorn.js';\n\nexport type TokenOrComment = Acorn.Token|Acorn.Comment;\n\n/**\n * The tokenizer in Acorn does not allow you to peek into the next token.\n * We use the peekToken method to determine when to stop formatting a\n * particular block of code.\n *\n * To remedy the situation, we implement the peeking of tokens ourselves.\n * To do so, whenever we call `nextToken`, we already retrieve the token\n * after it (in `bufferedToken`), so that `_peekToken` can check if there\n * is more work to do.\n *\n * There are 2 catches:\n *\n * 1. in the constructor we need to start the initialize the buffered token,\n *    such that `peekToken` on the first call is able to retrieve it. However,\n * 2. comments and tokens can arrive intermixed from the tokenizer. This usually\n *    happens when comments are the first comments of a file. In the scenario that\n *    the first comment in a file is a line comment attached to a token, we first\n *    receive the token and after that we receive the comment. However, when tokenizing\n *    we should reverse the order and return the comment, before the token.\n *\n * All that is to say that the `bufferedToken` is only used for *true* tokens.\n * We mimic comments to be tokens to fix the reordering issue, but we store these\n * separately to keep track of them. Any call to `nextTokenInternal` will figure\n * out whether the next token should be the preceding comment or not.\n */\nexport class AcornTokenizer {\n  readonly #content: string;\n  readonly #comments: Acorn.Comment[];\n  #tokenizer: {\n    getToken(): Acorn.Token,\n    [Symbol.iterator](): Iterator<Acorn.Token>,\n  };\n  #textCursor: TextUtils.TextCursor.TextCursor;\n  #tokenLineStartInternal: number;\n  #tokenLineEndInternal: number;\n  #tokenColumnStartInternal: number;\n  #bufferedToken?: TokenOrComment;\n\n  constructor(content: string) {\n    this.#content = content;\n    this.#comments = [];\n    this.#tokenizer =\n        Acorn.tokenizer(this.#content, {onComment: this.#comments, ecmaVersion: ECMA_VERSION, allowHashBang: true});\n    const contentLineEndings = Platform.StringUtilities.findLineEndingIndexes(this.#content);\n    this.#textCursor = new TextUtils.TextCursor.TextCursor(contentLineEndings);\n    this.#tokenLineStartInternal = 0;\n    this.#tokenLineEndInternal = 0;\n    this.#tokenColumnStartInternal = 0;\n    // If the first \"token\" should be a comment, we don't want to shift\n    // the comment from the array (which happens in `nextTokenInternal`).\n    // Therefore, we should bail out from retrieving the token if this\n    // is the case.\n    //\n    // However, sometimes we have leading comments that are attached to tokens\n    // themselves. In that case, we first retrieve the actual token, before\n    // we see the comment itself. In that case, we should proceed and\n    // initialize `bufferedToken` as normal, to allow us to fix the reordering.\n    if (this.#comments.length === 0) {\n      this.#nextTokenInternal();\n    }\n  }\n\n  static punctuator(token: Acorn.Token, values?: string): boolean {\n    return token.type !== Acorn.tokTypes.num && token.type !== Acorn.tokTypes.regexp &&\n        token.type !== Acorn.tokTypes.string && token.type !== Acorn.tokTypes.name && !token.type.keyword &&\n        (!values || (token.type.label.length === 1 && values.indexOf(token.type.label) !== -1));\n  }\n\n  static keyword(token: Acorn.Token, keyword?: string): boolean {\n    return Boolean(token.type.keyword) && token.type !== Acorn.tokTypes['_true'] &&\n        token.type !== Acorn.tokTypes['_false'] && token.type !== Acorn.tokTypes['_null'] &&\n        (!keyword || token.type.keyword === keyword);\n  }\n\n  static identifier(token: TokenOrComment, identifier?: string): boolean {\n    return token.type === Acorn.tokTypes.name && (!identifier || token.value === identifier);\n  }\n\n  static lineComment(token: TokenOrComment): boolean {\n    return token.type === 'Line';\n  }\n\n  static blockComment(token: TokenOrComment): boolean {\n    return token.type === 'Block';\n  }\n\n  #nextTokenInternal(): TokenOrComment|undefined {\n    if (this.#comments.length) {\n      const nextComment = this.#comments.shift();\n      // If this was the last comment to process, we need to make\n      // sure to update our `bufferedToken` to become the actual\n      // token. This only happens when we are processing the very\n      // first comment of a file (usually a hashbang comment)\n      // in which case we don't have to fix the reordering of tokens.\n      if (!this.#bufferedToken && this.#comments.length === 0) {\n        this.#bufferedToken = this.#tokenizer.getToken();\n      }\n      return nextComment;\n    }\n    const token = this.#bufferedToken;\n    this.#bufferedToken = this.#tokenizer.getToken();\n    return token;\n  }\n\n  nextToken(): TokenOrComment|null {\n    const token = this.#nextTokenInternal();\n    if (!token || token.type === Acorn.tokTypes.eof) {\n      return null;\n    }\n\n    this.#textCursor.advance(token.start);\n    this.#tokenLineStartInternal = this.#textCursor.lineNumber();\n    this.#tokenColumnStartInternal = this.#textCursor.columnNumber();\n\n    this.#textCursor.advance(token.end);\n    this.#tokenLineEndInternal = this.#textCursor.lineNumber();\n    return token;\n  }\n\n  peekToken(): TokenOrComment|null {\n    if (this.#comments.length) {\n      return this.#comments[0];\n    }\n    if (!this.#bufferedToken) {\n      return null;\n    }\n    return this.#bufferedToken.type !== Acorn.tokTypes.eof ? this.#bufferedToken : null;\n  }\n\n  tokenLineStart(): number {\n    return this.#tokenLineStartInternal;\n  }\n\n  tokenLineEnd(): number {\n    return this.#tokenLineEndInternal;\n  }\n\n  tokenColumnStart(): number {\n    return this.#tokenColumnStartInternal;\n  }\n}\n\nexport const ECMA_VERSION = 2022;\n"],
  "mappings": "AAIA;AACA;AACA;AA6BO,4BAAqB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAa1B,YAAY,SAAiB;AAC3B,oBAAgB;AAChB,qBAAiB;AACjB,sBACI,MAAM,UAAU,eAAe,EAAC,WAAW,gBAAgB,aAAa,cAAc,eAAe;AACzG,UAAM,qBAAqB,SAAS,gBAAgB,sBAAsB;AAC1E,uBAAmB,IAAI,UAAU,WAAW,WAAW;AACvD,mCAA+B;AAC/B,iCAA6B;AAC7B,qCAAiC;AAUjC,QAAI,eAAe,WAAW,GAAG;AAC/B;AAAA;AAAA;AAAA,SAIG,WAAW,OAAoB,QAA0B;AAC9D,WAAO,MAAM,SAAS,MAAM,SAAS,OAAO,MAAM,SAAS,MAAM,SAAS,UACtE,MAAM,SAAS,MAAM,SAAS,UAAU,MAAM,SAAS,MAAM,SAAS,QAAQ,CAAC,MAAM,KAAK,WACzF,EAAC,UAAW,MAAM,KAAK,MAAM,WAAW,KAAK,OAAO,QAAQ,MAAM,KAAK,WAAW;AAAA;AAAA,SAGlF,QAAQ,OAAoB,SAA2B;AAC5D,WAAO,QAAQ,MAAM,KAAK,YAAY,MAAM,SAAS,MAAM,SAAS,YAChE,MAAM,SAAS,MAAM,SAAS,aAAa,MAAM,SAAS,MAAM,SAAS,YACxE,EAAC,WAAW,MAAM,KAAK,YAAY;AAAA;AAAA,SAGnC,WAAW,OAAuB,YAA8B;AACrE,WAAO,MAAM,SAAS,MAAM,SAAS,QAAS,EAAC,cAAc,MAAM,UAAU;AAAA;AAAA,SAGxE,YAAY,OAAgC;AACjD,WAAO,MAAM,SAAS;AAAA;AAAA,SAGjB,aAAa,OAAgC;AAClD,WAAO,MAAM,SAAS;AAAA;AAAA,uBAGuB;AAC7C,QAAI,eAAe,QAAQ;AACzB,YAAM,cAAc,eAAe;AAMnC,UAAI,CAAC,uBAAuB,eAAe,WAAW,GAAG;AACvD,8BAAsB,gBAAgB;AAAA;AAExC,aAAO;AAAA;AAET,UAAM,QAAQ;AACd,0BAAsB,gBAAgB;AACtC,WAAO;AAAA;AAAA,EAGT,YAAiC;AAC/B,UAAM,QAAQ;AACd,QAAI,CAAC,SAAS,MAAM,SAAS,MAAM,SAAS,KAAK;AAC/C,aAAO;AAAA;AAGT,qBAAiB,QAAQ,MAAM;AAC/B,mCAA+B,iBAAiB;AAChD,qCAAiC,iBAAiB;AAElD,qBAAiB,QAAQ,MAAM;AAC/B,iCAA6B,iBAAiB;AAC9C,WAAO;AAAA;AAAA,EAGT,YAAiC;AAC/B,QAAI,eAAe,QAAQ;AACzB,aAAO,eAAe;AAAA;AAExB,QAAI,CAAC,qBAAqB;AACxB,aAAO;AAAA;AAET,WAAO,oBAAoB,SAAS,MAAM,SAAS,MAAM,sBAAsB;AAAA;AAAA,EAGjF,iBAAyB;AACvB,WAAO;AAAA;AAAA,EAGT,eAAuB;AACrB,WAAO;AAAA;AAAA,EAGT,mBAA2B;AACzB,WAAO;AAAA;AAAA;AAIJ,aAAM,eAAe;",
  "names": []
}
